{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edc16590-7c73-420a-9e5f-d0b98090c91d",
   "metadata": {},
   "source": [
    "# CosmoDC realizations\n",
    "Jaime Ruiz Zapatero - LSST 2024 July Meeting\n",
    "\n",
    "### What does this tutorial do?\n",
    "The goal of this tutorial is to show you generate possible n(z) realizations of the lens and sources photometric samples of Prat et al, 2022 (2212.09345).\n",
    "\n",
    "In order to do so we will use the BPZ and FlexZBoost catalogs of photometric redshifts for the CosmoDC2 simulations generated by Sam Schmidt. These catalogs preceed the RAIL tools but their outoput is equivalent. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be00926e",
   "metadata": {},
   "source": [
    "\n",
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90839929-037a-4a44-9ae4-1cc65ac11579",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9fae4398-9830-4c38-be33-c37ee47dbb25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import GCRCatalogs\n",
    "from GCR import GCRQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7f09a6-5b43-4cc7-b92a-67aca7c1da8d",
   "metadata": {},
   "source": [
    "## Load catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f3db7b-28a8-4174-b474-a80bf8e48d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CosmoDC2\n",
    "# BPZ\n",
    "cat = GCRCatalogs.load_catalog('CosmoDC2_v1.1.4_image_with_photozs_v1')\n",
    "# FlexZBoost\n",
    "#cat = GCRCatalogs.load_catalog('CosmoDC2_v1.1.4_image_with_photozs_flexzboost_v1')\n",
    "photo_cat = cat.get_quantities(['galaxy_id', 'photoz_pdf'], return_iterator=True)\n",
    "#basic_cuts = [GCRQuery('photoz_mask==1')]\n",
    "\n",
    "# Assign to tomo bins and save\n",
    "save_to = \"/pscratch/sd/j/jaimerz/CosmoDC2_catalogs/{}_tracks\".format(sample)\n",
    "zgrid = cat.photoz_pdf_bin_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c002aa8-7383-4440-9fcb-63973c88f0cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Judit's catalog\n",
    "sample = \"shear\"\n",
    "path_2_cat = \"/global/cfs/cdirs/lsst/groups/WL/projects/star-challenge/cosmodc2/TXPipe-full-output/\"\n",
    "fname = path_2_cat+\"binned_{}_catalog.hdf5\".format(sample)\n",
    "hf = h5py.File(fname, \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9664be-5d7e-4891-a773-be361d6f7efe",
   "metadata": {},
   "source": [
    "## Reduce the tracks to something managable\n",
    "\n",
    "First we cross match the ID's in the BPZ and FlexZBoost catalogs to the lens and source samples of Prat et al, 2022 in each tomographic bin. This allows us to avoid having to worry about assigning objects to tomographic objects ourselves. Since the CosmoDC2 catalogs are so large, we first cross match each track in the catalog to a tomographic and then we combine the all files associated with the same tomographic bin into a single catalog. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c617ddea-1be7-4fbc-98c8-d5d1343c329b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_tracks(hf, photo_cat, save_to)\n",
    "    for i, photo_q in enumerate(photo_cat):\n",
    "        candidate_fname = save_to+\"/lens_0_{}.npz\".format(i)\n",
    "        if os.path.isfile(candidate_fname):\n",
    "            pass\n",
    "        else:\n",
    "            ids = photo_q['galaxy_id']\n",
    "            sel_0 = np.isin(ids, hf[\"lens\"][\"bin_0\"][\"id\"])\n",
    "            sel_1 = np.isin(ids, hf[\"lens\"][\"bin_1\"][\"id\"])\n",
    "            sel_2 = np.isin(ids, hf[\"lens\"][\"bin_2\"][\"id\"])\n",
    "            sel_3 = np.isin(ids, hf[\"lens\"][\"bin_3\"][\"id\"])\n",
    "            sel_4 = np.isin(ids, hf[\"lens\"][\"bin_4\"][\"id\"])\n",
    "            id_0 = ids[sel_0]\n",
    "            id_1 = ids[sel_1]\n",
    "            id_2 = ids[sel_2]\n",
    "            id_3 = ids[sel_3]\n",
    "            id_4 = ids[sel_4]\n",
    "            photoz_0 = list(photo_q['photoz_pdf'][sel_0])\n",
    "            photoz_1 = list(photo_q['photoz_pdf'][sel_1])\n",
    "            photoz_2 = list(photo_q['photoz_pdf'][sel_2])\n",
    "            photoz_3 = list(photo_q['photoz_pdf'][sel_3])\n",
    "            photoz_4 = list(photo_q['photoz_pdf'][sel_4])\n",
    "\n",
    "            #pzdict_0 = {'id': id_0, 'pdf': photoz_0}\n",
    "            #pzdict_1 = {'id': id_1, 'pdf': photoz_1}\n",
    "            #pzdict_2 = {'id': id_2, 'pdf': photoz_2}\n",
    "            #pzdict_3 = {'id': id_3, 'pdf': photoz_3}\n",
    "            #pzdict_4 = {'id': id_4, 'pdf': photoz_4}\n",
    "\n",
    "            fname_0 = save_to+\"/lens_0_{}\".format(i)\n",
    "            fname_1 = save_to+\"/lens_1_{}\".format(i)\n",
    "            fname_2 = save_to+\"/lens_2_{}\".format(i)\n",
    "            fname_3 = save_to+\"/lens_3_{}\".format(i)\n",
    "            fname_4 = save_to+\"/lens_4_{}\".format(i)\n",
    "\n",
    "            np.savez(fname_0, ids=id_0, pdf=photoz_0)\n",
    "            np.savez(fname_1, ids=id_1, pdf=photoz_1)\n",
    "            np.savez(fname_2, ids=id_2, pdf=photoz_2)\n",
    "            np.savez(fname_3, ids=id_3, pdf=photoz_3)\n",
    "            np.savez(fname_4, ids=id_4, pdf=photoz_4)\n",
    "\n",
    "            print(i, len(id_0), len(id_1), len(id_2), \n",
    "                 len(id_3), len(id_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bc7129-646c-48eb-9bc3-c72a2f006861",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_tracks(hf, photo_cat, save_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4a72f3-163e-4e10-8863-d785158654e5",
   "metadata": {},
   "source": [
    "## Compose tracks into tomo bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7e31eba-21e8-4e27-b607-36ff8511a6ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_tracks(load_from, save_to):\n",
    "    for tomo_bin in np.arange(0, 5):\n",
    "        tomo_name = \"/lens_{}.npz\".format(tomo_bin)\n",
    "        tomo_path = save_to+tomo_name\n",
    "        if os.path.isfile(tomo_path):\n",
    "                pass\n",
    "        else:\n",
    "            print(tomo_bin)\n",
    "            track = 0\n",
    "            candidate_file = load_from+\"/lens_{}_{}.npz\".format(tomo_bin, track)\n",
    "            total_ids = np.array([])\n",
    "            total_pdfs = list([])\n",
    "            while os.path.isfile(candidate_file):\n",
    "                pzdict = dict(np.load(candidate_file, allow_pickle=True))\n",
    "                ids = pzdict['ids']\n",
    "                pdfs = pzdict['pdf']\n",
    "                total_ids = np.append(total_ids, ids)\n",
    "                for pdf in pdfs:\n",
    "                    total_pdfs.append(pdf)\n",
    "                print((track, len(total_ids)), end='\\r', flush=True)\n",
    "                track = track + 1\n",
    "                candidate_file = load_from+\"/lens_{}_{}.npz\".format(tomo_bin, track)\n",
    "            tomo = {'ids': total_ids, 'pdfs':total_pdfs}\n",
    "            np.savez(tomo_path, ids=total_ids, pdfs=total_pdfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9c3568",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from = \"/pscratch/sd/j/jaimerz/CosmoDC2_catalogs/{}_tracks\".format(sample)\n",
    "save_to = \"/pscratch/sd/j/jaimerz/CosmoDC2_catalogs/{}\".format(sample)\n",
    "combine_tracks(load_from, save_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13147d57",
   "metadata": {},
   "source": [
    "## Make samples \n",
    "\n",
    "Once we have devided the BPZ and FlexZBoost catalogs into tomographic bins, we loop over each object in the catalogs and generate 1000 samples from each indivudual p(z). This effectively generates 1000 possible catalogs distributed according to the uncertaintity in the photometric redshift of each object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "861c0678-7fac-4978-85c0-e0c4dbdcd565",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_samples(load_from, save_to,\n",
    "                   normalize=False, n_samples=1_000):\n",
    "    rs = np.array([np.random.uniform() for i in np.arange(n_samples)])\n",
    "    for i in range(0, 5):\n",
    "        candidate_fname = save_to+\"/{}_{}.npz\".format(sample, i)\n",
    "        if os.path.isfile(candidate_fname):\n",
    "            pass\n",
    "        else:\n",
    "            print(i)\n",
    "            tomo_name = \"/{}_{}.npz\".format(sample, i)\n",
    "            tomo = np.load(load_from+tomo_name, allow_pickle=True)\n",
    "            pdfs = np.array(tomo['pdfs'])\n",
    "            print(\"Generate samples\")\n",
    "            photo_samples = []\n",
    "            for j, pdf in enumerate(pdfs):\n",
    "                if j % 100 == 0:\n",
    "                    print(j, end='\\r', flush=True)\n",
    "                norm = np.sum(pdf)\n",
    "                if normalize:\n",
    "                    pdf = pdf/norm\n",
    "                cdf = np.cumsum(pdf) # Cumulative distribution function\n",
    "                cdf_i = interp1d(cdf, zgrid, fill_value=\"extrapolate\") # Inverse CDF\n",
    "                photo_samples.append(cdf_i(rs)) # Generate sample from photo-z PDF\n",
    "            photo_samples = np.array(photo_samples)\n",
    "            np.savez(candidate_fname,\n",
    "                    samples=photo_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2322e8c9-3310-4fff-94e4-e1ff8cc8bf2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Generate samples\n",
      "4528700\r"
     ]
    }
   ],
   "source": [
    "load_from = \"/pscratch/sd/j/jaimerz/CosmoDC2_catalogs/{}_pdfs\".format(sample)\n",
    "save_to = \"/pscratch/sd/j/jaimerz/CosmoDC2_catalogs/{}_samples\".format(sample)\n",
    "make_samples(load_from, save_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7e7262-2d18-41a3-9840-5d37e5bcc288",
   "metadata": {},
   "source": [
    "## Make Histograms from samples\n",
    "\n",
    "Finally we bin each catalog in the ensemble to generate redshift distributions for the populations as a whole; i.e. the n(z). This gives us an esemble of 1000 possible n(z) for each sample that captures the photometric ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647b3510-c3c8-48b0-b097-3b3d24284e8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_hists(load_from, save_to, grids,\n",
    "              normalize=False):\n",
    "    for i, grid in enumerate(grids):\n",
    "        candidate_fname = save_to+\"/{}_{}.npz\".format(sample, i)\n",
    "        if os.path.isfile(candidate_fname):\n",
    "            pass\n",
    "        else:\n",
    "            photo_samples = np.load(load_from+\"/{}_{}.npz\".format(sample, i))\n",
    "            photo_samples = photo_samples[\"samples\"]\n",
    "            zbins = np.linspace(grid[0],grid[1], 26)\n",
    "            znodes = 0.5*(zbins[1:]+zbins[:-1])\n",
    "            photo_hists = []\n",
    "            for j, samples in enumerate(photo_samples.T):\n",
    "                print(j, end='\\r', flush=True)\n",
    "                photo_hist = np.histogram(samples, bins=zbins, density=False)[0]\n",
    "                photo_hists.append(photo_hist)\n",
    "            photo_hists = np.array(photo_hists)\n",
    "            if normalize:\n",
    "                photo_hists_norms = np.array([np.sum(hist) for hist in photo_hists])\n",
    "                photo_hists = photo_hists.T/photo_hists_norms\n",
    "            else:\n",
    "                photo_hists = photo_hists.T\n",
    "            np.savez(candidate_fname,\n",
    "                     zgrid=zbins,\n",
    "                     znodes=znodes,\n",
    "                     photo_hists=photo_hists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d427788-dcd1-4a69-b229-029643bd2c18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#grids_lens = [[0.0, 0.6],\n",
    "#        [0.0, 1.0],\n",
    "#        [0.3, 1.0],\n",
    "#        [0.3, 1.3],\n",
    "#        [0.5, 1.5]]\n",
    "\n",
    "grids_shear = [[0.0, 2.0],\n",
    "         [0.0, 2.0],\n",
    "         [0.0, 2.0],\n",
    "         [0.0, 2.0],\n",
    "         [0.0, 3.0]]\n",
    "\n",
    "load_from = \"/pscratch/sd/j/jaimerz/CosmoDC2_catalogs/{}_samples\".format(sample)\n",
    "save_to = \"/pscratch/sd/j/jaimerz/CosmoDC2_catalogs/{}_hists\".format(sample)\n",
    "make_hists(load_from, save_to, grids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3721f4ed-a13b-41eb-b4ef-0f09cf443847",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239fb85d-6fd5-4e8e-8a53-7ea503e91df8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lens_0 = np.load(\"/pscratch/sd/j/jaimerz/CosmoDC2_catalogs/lens_hists/{}_0.npz\".format(sample), allow_pickle=True)\n",
    "lens_1 = np.load(\"/pscratch/sd/j/jaimerz/CosmoDC2_catalogs/lens_hists/{}_1.npz\".format(sample), allow_pickle=True)\n",
    "lens_2 = np.load(\"/pscratch/sd/j/jaimerz/CosmoDC2_catalogs/lens_hists/{}_2.npz\".format(sample), allow_pickle=True)\n",
    "lens_3 = np.load(\"/pscratch/sd/j/jaimerz/CosmoDC2_catalogs/lens_hists/{}_3.npz\".format(sample), allow_pickle=True)\n",
    "lens_4 = np.load(\"/pscratch/sd/j/jaimerz/CosmoDC2_catalogs/lens_hists/{}_4.npz\".format(sample), allow_pickle=True)\n",
    "\n",
    "lenses = {'lens_0': lens_0,\n",
    "          'lens_1': lens_1,\n",
    "          'lens_2': lens_2,\n",
    "          'lens_3': lens_3,\n",
    "          'lens_4': lens_4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942c5746-1176-4bf3-89e7-8038cde178a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fig = plt.figure(figsize=(15,8))\n",
    "colors = ['skyblue', 'teal', 'blue', 'purple', 'darkviolet']\n",
    "for i, key in enumerate(list(lenses.keys())):\n",
    "    tomo = lenses[key]\n",
    "    photo_dz = np.mean(np.diff(tomo['znodes']))\n",
    "    spec_dz = np.mean(np.diff(zgrid))\n",
    "    alpha = photo_dz/spec_dz\n",
    "    #plt.plot(tomo['spec_znodes'], alpha*tomo['spec_hist'], 'k-')\n",
    "    plt.plot(tomo['znodes'], tomo['photo_hists'], '-', color=colors[i], alpha=0.01)\n",
    "    plt.plot(tomo['znodes'], np.mean(tomo['photo_hists'], axis=1), '-', color=colors[i], label=key)\n",
    "\n",
    "#nzsum = np.sum(fz_df['pdf'])\n",
    "#plt.plot(zgrid,nzsum,c='b',label=f\"i<{magcut} sum p(z)\")\n",
    "\n",
    "plt.xlim([0.0, 3.0])\n",
    "plt.title(\"CosmoDC2\")\n",
    "plt.xlabel(\"redshift\",fontsize=18)\n",
    "plt.ylabel(\"N(z)\",fontsize=18)\n",
    "plt.legend(loc = 'upper right',fontsize=16);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d338aa-d11e-4c7b-9314-e8f022e145ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925c7492-373e-4fd4-a02b-e6c623a8be10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desc-python",
   "language": "python",
   "name": "desc-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
