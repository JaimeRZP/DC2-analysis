{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code investigates the shape measurement performance of the DM stack on the DR2 imaging data.  It has a few steps:\n",
    " - Load a star catalog and a galaxy catalog from the imaging area\n",
    " - Load the extragalactic catalog and truth catalog over the same area\n",
    " - Match the imaging and EGC catalogs \n",
    " - Measure the galaxy-galaxy shear correlation functions of the two galaxy catalogs\n",
    " - Measure the \"rho statistics\" -- correlation functions of the PSF and star shapes that diagnose PSF leakage into the cosmic shear signal\n",
    " - Measure the calibration factors that remove measurement bias from the shape measurement on images\n",
    " - Correct the galaxy-galaxy shear CF from the imaging data and compare the corrected version to the EGC CF\n",
    " - Measure the correlation function of the EGC over the same area, using all EGC galaxies reweighted to the same size and flux distribution as the measured galaxies, to further look for selection bias\n",
    " \n",
    "Many of these steps borrow heavily from other DC2 tutorials, as listed in the code comments.\n",
    "\n",
    "We begin by loading up the code we'll need. Stile will eventually be in the DESC environment but you may need to load it by hand at first by adding the path to sys.path.  The desc-stack kernel is most likely to have the dependencies you need for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys\n",
    "sys.path.insert(0, '')\n",
    "# Could not get this to work with anything less specific...\n",
    "sys.path.insert(0, '/global/homes/m/msimet/.local/lib/python3.6/site-packages')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import FoFCatalogMatching\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as op\n",
    "with warnings.catch_warnings():\n",
    "    # Stile throws up a bunch of matplotlib warnings that we can just ignore\n",
    "    warnings.filterwarnings('ignore')\n",
    "    import stile\n",
    "from utils.paired_catalogs import get_catalogs\n",
    "\n",
    "figsize_x, figsize_y = plt.gcf().get_size_inches()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you look at LSST_stack_matching.py, you'll see that this is a large block of code that retrieves\n",
    "# data from the butler and from various catalogs, computes shapes where necessary, applies cuts, and \n",
    "# finally returns these catalogs. The default settings and default cuts for get_catalogs() should be \n",
    "# sensible, but you can look at the docstring for that function for more info.\n",
    "\n",
    "# This takes a few minutes to run\n",
    "galaxy_catalog, star_catalog, egc_catalog, truth_catalog = get_catalogs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match the truth catalog to the DM catalog, and the EGC to the truth catalog\n",
    "\n",
    "matches = FoFCatalogMatching.match(\n",
    "    catalog_dict={'truth': truth_catalog, 'object': galaxy_catalog},\n",
    "    linking_lengths=1.0,\n",
    "    catalog_len_getter=lambda x: len(x['ra']),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, find the one-to-one matches.\n",
    "# We could probably be more clever and try to figure out what's going on with the non-matches,\n",
    "# because this probably has a weird selection, but it should be good enough for now.\n",
    "# This (like the above box) is from the FoF matching tutorial,\n",
    "# https://github.com/LSSTDESC/DC2-analysis/blob/master/tutorials/matching_fof.ipynb\n",
    "truth_mask = matches['catalog_key'] == 'truth'\n",
    "object_mask = ~truth_mask\n",
    "\n",
    "n_groups = matches['group_id'].max() + 1\n",
    "n_truth = np.bincount(matches['group_id'][truth_mask], minlength=n_groups)\n",
    "n_object = np.bincount(matches['group_id'][object_mask], minlength=n_groups)\n",
    "\n",
    "one_to_one_group_mask = np.in1d(matches['group_id'], np.flatnonzero((n_truth == 1) & (n_object == 1)))\n",
    "truth_idx = matches['row_index'][one_to_one_group_mask & truth_mask]\n",
    "object_idx = matches['row_index'][one_to_one_group_mask & object_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a pandas DataFrame that merges all the catalogs\n",
    "truth_table = pd.DataFrame(truth_catalog).iloc[truth_idx].reset_index(drop=True)\n",
    "object_table = pd.DataFrame(galaxy_catalog).iloc[object_idx].reset_index(drop=True)\n",
    "merged_table = pd.merge(truth_table, object_table, left_index=True, right_index=True, suffixes=('_truth', '_object'))\n",
    "merged_table = pd.merge(merged_table, pd.DataFrame(egc_catalog), 'inner', left_on='object_id', right_on='galaxy_id', suffixes=('', '_egc'))\n",
    "# some EGC things are named \"_true\" and having both \"_true\" and \"_truth\" is confusing!\n",
    "merged_table = merged_table.rename(columns=lambda x: x[:-5]+'_egc' if x[-5:] == '_true' else x) \n",
    "# Make some column names easier to type\n",
    "merged_table = merged_table.rename(columns={\"ext_shapeHSM_HsmShapeRegauss_e1\" : \"e1_object\", \n",
    "                                            \"ext_shapeHSM_HsmShapeRegauss_e2\" : \"e2_object\",\n",
    "                                            \"ellipticity_1_egc\": \"e1_egc\",\n",
    "                                            \"ellipticity_2_egc\": \"e2_egc\"})\n",
    "    \n",
    "print(\"Number of matches: {} from {} DM galaxies and {} truth galaxies\".format(\n",
    "            len(merged_table['ra_truth']), len(galaxy_catalog['ra']), len(truth_catalog['ra'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will measure the calibration factors we need to go from the measured HSM shapes to the catalog shapes.  We usually use a linear decomposition: $m$ and $c$.  Most shape measurement codes have been found to be linear in the weak lensing regime, so this should be sufficient for our purposes.  That means that for a given intrinsic shape $g^{\\rm true}$, what we actually measure is:\n",
    "\n",
    "$$ g^{\\rm meas} = (1+m)g^{\\rm true} + c $$\n",
    "\n",
    "The $c$ portion also has a dependence on the PSF ellipticity that we will parameterize through $alpha$, so:\n",
    "\n",
    "$$ g^{\\rm meas} = (1+m)g^{\\rm true} + \\alpha e^{\\rm PSF} + c $$\n",
    "\n",
    "We have an advantage here in that we have real pairs of input and output shapes to measure these coefficients on.  We will assume there is no difference between the two components of the ellipticity (which should be close enough for this exercise).  However, there is one more component to care about.  The shape in the catalogs is ellipticity, not distortion (see [Bernstein & Jarvis 2002](https://arxiv.org/abs/astro-ph/0107431) for more), so we need to correct the galaxy shapes for the different definition.  This factor includes a factor of two and a component called the _responsivity_ that depends on the per-component RMS distortion:\n",
    "\n",
    "$$ \\mathcal{R} \\approx 1-e_{\\rm rms}^2 $$\n",
    "\n",
    "We would want this to be weighted if we were weighting galaxies, but in this tutorial, we are not.  So in the end our full equation is:\n",
    "\n",
    "$$ \\frac{g^{\\rm meas}}{2\\mathcal{R}} = (1+m)g^{\\rm true} + \\alpha e^{\\rm PSF} + c $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responsivity = 1-np.mean(np.concatenate([merged_table['e1_object']**2, merged_table['e2_object']**2]))\n",
    "print(\"Responsivity = {}\".format(responsivity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_model(x, m, alpha, c):\n",
    "    xtrue = x[0]\n",
    "    xpsf = x[1]\n",
    "    return 2*responsivity*((1+m)*xtrue + alpha*xpsf + c)\n",
    "\n",
    "# The EGC and object catalogs seem to have different sign conventions\n",
    "e_egc_all = np.concatenate([merged_table['e1_egc'], merged_table['e2_egc']])\n",
    "psf_e_all = np.concatenate([-1*merged_table['psf_e1'], merged_table['psf_e2']])\n",
    "e_obj_all =  np.concatenate([-1*merged_table['e1_object'], merged_table['e2_object']])\n",
    "param, _ =  op.curve_fit(bias_model, [e_egc_all, psf_e_all], e_obj_all)\n",
    "\n",
    "m = param[0]\n",
    "alpha = param[1]\n",
    "c = param[2]\n",
    "\n",
    "print(\"m={}, alpha={}, c={}\".format(*param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_psf_e1 = merged_table['psf_e1'].mean()\n",
    "avg_psf_e2 = merged_table['psf_e2'].mean()\n",
    "\n",
    "# Plot what these biases actually look like\n",
    "fig = plt.figure(figsize=[2*figsize_x, figsize_y])\n",
    "ax = fig.add_subplot(121)\n",
    "ax.hist2d(responsivity*merged_table['e1_egc'], -merged_table['e1_object']/2/responsivity, bins=20)\n",
    "ax.plot(2*merged_table['e1_egc'], 2*(1+m)*merged_table['e1_egc']+alpha*avg_psf_e1+c, color='black')\n",
    "ax.set_xlabel(\"EGC g1\")\n",
    "ax.set_ylabel(\"Object g1\")\n",
    "ax.set_ylim((-1, 1))\n",
    "ax = fig.add_subplot(122)\n",
    "ax.hist2d(merged_table['e2_egc'], merged_table['e2_object']/2/responsivity, bins=20)\n",
    "ax.plot(2*merged_table['e2_egc'], 2*(1+m)*merged_table['e2_egc']+alpha*avg_psf_e2+c, color='black')\n",
    "ax.set_xlabel(\"EGC g2\")\n",
    "ax.set_ylabel(\"Object g2\")\n",
    "ax.set_ylim((-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, correlation functions. We'll use Stile to do this.  Stile's correlation function code wraps TreeCorr, but it has some built-in plotting and data-formatting functions that save us some lines of code here.\n",
    "\n",
    "We need to define the binning for the correlation function.  I've gone for 1/5 of the extent of the catalog in declination for the max distance (possibly large enough to see edge effects anyway), using 20 bins to cover an order of magnitude in angular distance.  We'll also need to rename some columns, since Stile expects specific names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick some good bin edges\n",
    "star_catalog = pd.DataFrame(star_catalog)\n",
    "star_catalog['w'] = np.ones_like(star_catalog['ra'])\n",
    "star_catalog_stile = star_catalog.rename(columns={'e1': 'g1', 'e2': 'g2', 'psf_e1': 'psf_g1', 'psf_e2': 'psf_g2'}).to_records()\n",
    "# Responsivity for round objects is 1, but we still need that factor of 2!\n",
    "star_catalog_stile['g1'] /= 2\n",
    "star_catalog_stile['g2'] /= 2\n",
    "min_ra = star_catalog['ra'].min()\n",
    "max_ra = star_catalog['ra'].max()\n",
    "min_dec = star_catalog['dec'].min()\n",
    "max_dec = star_catalog['dec'].max()\n",
    "\n",
    "max_sep = 0.2*(max_dec-min_dec)\n",
    "min_sep = 0.1*max_sep\n",
    "nbins = 20\n",
    "\n",
    "# Make a dict of TreeCorr parameters that we can pass to Stile\n",
    "corrfunc_kwargs = {'ra_units': 'degrees', 'dec_units': 'degrees',\n",
    "                   'min_sep': min_sep, 'max_sep': max_sep, 'sep_units': 'degrees', 'nbins': nbins }\n",
    "\n",
    "rho1 = stile.CorrelationFunctionSysTest(\"Rho1\")\n",
    "rho2 = stile.CorrelationFunctionSysTest(\"Rho2\")\n",
    "rho3 = stile.CorrelationFunctionSysTest(\"Rho3\")\n",
    "rho4 = stile.CorrelationFunctionSysTest(\"Rho4\")\n",
    "rho5 = stile.CorrelationFunctionSysTest(\"Rho5\")\n",
    "\n",
    "rho1_res = rho1(star_catalog_stile, **corrfunc_kwargs)\n",
    "rho2_res = rho2(star_catalog_stile, **corrfunc_kwargs)\n",
    "rho3_res = rho3(star_catalog_stile, **corrfunc_kwargs)\n",
    "rho4_res = rho4(star_catalog_stile, **corrfunc_kwargs)\n",
    "rho5_res = rho5(star_catalog_stile, **corrfunc_kwargs)\n",
    "\n",
    "# When you correct correlation functions for additive and multiplicative bias, the additive is generally stable\n",
    "# and can be done per-object, while the multiplicative is not stable and should be done in ensemble.  Since we measured\n",
    "# m and c from the whole ensemble, though, we can just do the subtraction and division right now for m and c, and \n",
    "# because the alpha term is additive, we can do that per-object right now, too.  And again, we need to flip\n",
    "# the e1 direction to make it comparable to the EGC.\n",
    "\n",
    "merged_table['e1_object_prime'] = -(merged_table['e1_object']/2/responsivity - c - alpha*merged_table['psf_e1'])/(1+m)\n",
    "merged_table['e2_object_prime'] = (merged_table['e2_object']/2/responsivity - c - alpha*merged_table['psf_e2'])/(1+m)\n",
    "merged_table['w'] = np.ones_like(merged_table['ra_egc'])\n",
    "\n",
    "merged_table_stile_obj = merged_table.rename(columns={'e1_object_prime': 'g1', 'e2_object_prime': 'g2', 'ra_object': 'ra', 'dec_object': 'dec'}).to_records()\n",
    "object_corrfunc = stile.CorrelationFunctionSysTest()\n",
    "object_corrfunc_res = object_corrfunc('gg', merged_table_stile_obj, **corrfunc_kwargs)\n",
    "\n",
    "merged_table_stile_egc = merged_table.rename(columns={'e1_egc': 'g1', 'e2_egc': 'g2', 'ra_egc': 'ra', 'dec_egc': 'dec'}).to_records()\n",
    "egc_corrfunc = stile.CorrelationFunctionSysTest()\n",
    "egc_corrfunc_res = egc_corrfunc('gg', merged_table_stile_egc, **corrfunc_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up some memory\n",
    "del star_catalog_stile\n",
    "del merged_table_stile_egc\n",
    "del merged_table_stile_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do these functions look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the interface presented here will change in the near future to rho1_res.plot()\n",
    "fig = rho1.plot(rho1_res)\n",
    "fig.suptitle('Rho 1')\n",
    "plt.clf()\n",
    "\n",
    "fig = rho2.plot(rho2_res)\n",
    "fig.suptitle('Rho 2')\n",
    "plt.clf()\n",
    "\n",
    "fig = rho3.plot(rho3_res)\n",
    "fig.suptitle('Rho 3')\n",
    "plt.clf()\n",
    "\n",
    "fig = rho4.plot(rho4_res)\n",
    "fig.suptitle('Rho 4')\n",
    "plt.clf()\n",
    "\n",
    "fig = rho5.plot(rho5_res)\n",
    "fig.suptitle('Rho 5')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = object_corrfunc.plot(object_corrfunc_res)\n",
    "fig.suptitle('Image-derived correlation function')\n",
    "plt.clf()\n",
    "\n",
    "fig = egc_corrfunc.plot(egc_corrfunc_res)\n",
    "fig.suptitle('EGC-derived correlation function')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following __[Jarvis et al (2015)](https://ui.adsabs.harvard.edu/#abs/arXiv:1507.05603)__, we define the correction to the correlation function as\n",
    "\n",
    "$$ \\delta \\xi_+(\\theta) = 2 \\left\\langle \\frac{T_{\\rm PSF}}{T_{\\rm gal}} \\frac{\\delta T_{\\rm PSF}}{T_{\\rm PSF}}\\right\\rangle \\xi_+(\\theta)  +  \\left\\langle \\frac{T_{\\rm PSF}}{T_{\\rm gal}} \\right\\rangle^2 \\rho_1(\\theta) - \\alpha  \\left\\langle \\frac{T_{\\rm PSF}}{T_{\\rm gal}}\\right\\rangle \\rho_2(\\theta) +  \\left\\langle \\frac{T_{\\rm PSF}}{T_{\\rm gal}} \\right\\rangle^2 \\rho_3 (\\theta) +  \\left\\langle \\frac{T_{\\rm PSF}}{T_{\\rm gal}}\\right\\rangle^2 \\rho_4(\\theta) - \\alpha  \\left\\langle \\frac{T_{\\rm PSF}}{T_{\\rm gal}}\\right\\rangle \\rho_5(\\theta) $$\n",
    "\n",
    "T represents the intensity-weighted second moment of the radius, called $R^2$ in an earlier paper by Paulin-Henriksson et al. (2008).  Handily for us, this is the quantity called \"sigma\" in the reGaussianization pipeline.  Following  Jarvis et al, we'll approximate that first expectation value as the multiplication of two expectation values:\n",
    "\n",
    "$$\\left\\langle \\frac{T_{\\rm PSF}}{T_{\\rm gal}} \\frac{\\delta T_{\\rm PSF}}{T_{\\rm PSF}}\\right\\rangle = \\left\\langle \\frac{T_{\\rm PSF}}{T_{\\rm gal}}\\right\\rangle \\left\\langle \\frac{\\delta T_{\\rm PSF}}{T_{\\rm PSF}}\\right\\rangle $$\n",
    "\n",
    "since we can't measure  the PSF modeling error at the locations of galaxies, and we can't measure galaxy size at the locations of stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xip_object = object_corrfunc_res['xip']/(1+2*m)\n",
    "# We don't have the galaxy shapes directly, but resolution, which we *do* have, is 1-TPSF/Tgal\n",
    "tpsf_tgal = np.mean(1-merged_table['ext_shapeHSM_HsmShapeRegauss_resolution'])\n",
    "tpsf_tgal_deltatpsf = tpsf_tgal*np.mean((star_catalog['psf_sigma']-star_catalog['sigma'])/star_catalog['sigma'])\n",
    "\n",
    "delta_xip = ( 2*tpsf_tgal_deltatpsf * xip_object + tpsf_tgal**2*(rho1_res['xip'] + rho3_res['xip'] + rho4_res['xip'])\n",
    "             - alpha*tpsf_tgal*(rho2_res['xip']+rho5_res['xip']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, the comparison.  For ease of reading the plot, we're only going to plot the errorbars for the corrected object-based shape-shape correlation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xip_gc = egc_corrfunc_res['xip']\n",
    "# Correct the measurement from the DRP for m biases as well as responsivity\n",
    "xip_object_corrected = (xip_object + delta_xip)\n",
    "\n",
    "xi_err_sq = (object_corrfunc_res['sigma_xi']**2*(1+4*tpsf_tgal_deltatpsf**2) + \n",
    "             tpsf_tgal**4*(rho1_res['sigma_xi']**2 + rho3_res['sigma_xi']**2 + rho4_res['sigma_xi']**2) -\n",
    "             alpha**2*tpsf_tgal**2*(rho2_res['sigma_xi']**2+rho5_res['sigma_xi']**2))\n",
    "\n",
    "x = egc_corrfunc_res['meanR [deg]']\n",
    "x_edges = np.concatenate(([x[0]**2/x[1]], np.sqrt(x[:1]*x[1:]), [x[-1]**2/x[-2]]))\n",
    "x_err = [x-x_edges[:-1], x_edges[1:]-x]\n",
    "plt.figure(figsize=(2*figsize_x, 2*figsize_y))\n",
    "plt.plot(x, np.abs(egc_corrfunc_res['xip']), label=\"Truth\", color=\"C0\") \n",
    "plt.errorbar(x, np.abs(xip_object_corrected), yerr=np.sqrt(xi_err_sq),\n",
    "             label=\"object, corrected\", color='C1')\n",
    "plt.plot(x, np.abs(xip_object), \n",
    "             label=\"object\", color='C2')\n",
    "plt.plot(x, np.abs(2*tpsf_tgal_deltatpsf*xip_object), \n",
    "             label=r\"$\\xi_+$ error term\", color='C3')\n",
    "plt.plot(x, np.abs(tpsf_tgal**2*rho1_res['xip']), \n",
    "             label=r\"$\\rho_1$ error term\", color='C4')\n",
    "plt.plot(x, np.abs(alpha*tpsf_tgal*rho2_res['xip']), \n",
    "             label=r\"$\\rho_2$ error term\", color='C5')\n",
    "plt.plot(x, np.abs(tpsf_tgal**2*rho3_res['xip']), \n",
    "             label=r\"$\\rho_3$ error term\", color='C6')\n",
    "plt.plot(x, np.abs(tpsf_tgal**2*rho4_res['xip']), \n",
    "             label=r\"$\\rho_4$ error term\", color='C7')\n",
    "plt.plot(x, np.abs(alpha*tpsf_tgal*rho5_res['xip']), \n",
    "             label=r\"$\\rho_5$ error term\", color='C8')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"R [deg]\")\n",
    "plt.ylabel(r\"$\\xi_+$\")\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can ask, what effect does selection have?  These previous plots were measured using only matched objects--but not all objects were matched.  Let's compute some correlation functions using *all* the objects in the given sky area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egc_catalog['w'] = np.ones_like(egc_catalog['ra_true'])\n",
    "for old, new in [('ra_true', 'ra'), ('dec_true', 'dec'), ('ellipticity_1_true', 'g1'), ('ellipticity_2_true', 'g2')]:\n",
    "    egc_catalog[new] = egc_catalog[old]\n",
    "egc_catalog_stile = np.rec.fromarrays(egc_catalog.values(), names=list(egc_catalog.keys()))\n",
    "egc_all_corrfunc = stile.CorrelationFunctionSysTest()\n",
    "egc_all_corrfunc_res = egc_all_corrfunc('gg', egc_catalog_stile, **corrfunc_kwargs)\n",
    "\n",
    "galaxy_catalog['w'] = np.ones_like(galaxy_catalog['ra'])\n",
    "for old, new in [('ext_shapeHSM_HsmShapeRegauss_e1', 'g1'), ('ext_shapeHSM_HsmShapeRegauss_e2', 'g2')]:\n",
    "    galaxy_catalog[new] = galaxy_catalog[old]\n",
    "galaxy_catalog_stile = np.rec.fromarrays(galaxy_catalog.values(), names=list(galaxy_catalog.keys()))\n",
    "galaxy_catalog_stile['g1'] = -(galaxy_catalog_stile['g1']/2/responsivity - c - alpha*galaxy_catalog_stile['psf_e1'])/(1+m)\n",
    "galaxy_catalog_stile['g2'] = (galaxy_catalog_stile['g2']/2/responsivity - c - alpha*galaxy_catalog_stile['psf_e2'])/(1+m)\n",
    "object_all_corrfunc = stile.CorrelationFunctionSysTest()\n",
    "object_all_corrfunc_res = object_all_corrfunc('gg', galaxy_catalog_stile, **corrfunc_kwargs)\n",
    "\n",
    "plt.figure(figsize=(2*figsize_x, 2*figsize_y))\n",
    "plt.errorbar(x, object_corrfunc_res['xip'], yerr=object_corrfunc_res['sigma_xi'], label=\"Matched DM objects\")\n",
    "plt.errorbar(x, object_all_corrfunc_res['xip'], yerr=object_all_corrfunc_res['sigma_xi'], label=\"All DM objects\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"R [deg]\")\n",
    "plt.ylabel(r\"$\\xi_+$\")\n",
    "#plt.yscale('symlog', linthreshy=1.E-4)\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.figure(figsize=(2*figsize_x, 2*figsize_y))\n",
    "plt.errorbar(x, egc_corrfunc_res['xip'], yerr=egc_corrfunc_res['sigma_xi'], label=\"Matched EGC objects\")\n",
    "plt.errorbar(x, egc_all_corrfunc_res['xip'], yerr=egc_all_corrfunc_res['sigma_xi'], label=\"All EGC objects\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"R [deg]\")\n",
    "plt.ylabel(r\"$\\xi_+$\")\n",
    "#plt.yscale('symlog', linthreshy=1.E-4)\n",
    "plt.xscale('log')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desc-stack",
   "language": "python",
   "name": "desc-stack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
