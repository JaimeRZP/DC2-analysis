{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DC2: Matching DIA vs Truth lightcurves\n",
    "<br> Author: **Bruno Sanchez** [bruno.sanchez@duke.edu]\n",
    "<br> Last verified to run: **10-15-2019**\n",
    "\n",
    "## What this notebook does\n",
    "- This notebook performs a coordinate match between the `diaObject` catalog and the DC2 `truth variable summary` catalog, both accessible through GCR catalog tool. To do this we are using `astropy.coordinates.Skycoord` object, making possible to match both catalogs at once.  \n",
    "\n",
    "- After that we ask for the lightcurves of each element of each catalog, and perform a _time match_. This is done by requiring that the MJD difference between the DIA and Truth cat is less than 5 minutes. \n",
    "\n",
    "- Finally we calculate some metrics on the objects recovered.\n",
    "\n",
    "## Some more detail\n",
    "\n",
    "### Time for processing\n",
    "\n",
    "The time for processing is quite long, and you can actually skip the long cell that performs the individual time-matching for each epoch and load the table itself from the `.csv` file already generated\n",
    "\n",
    "### Catalogs used\n",
    "\n",
    "We used the following catalogs\n",
    "* diaSrc => `dc2_dia_source_run1.2p_test`\n",
    "* diaObject => `dc2_dia_object_run1.2p_test`\n",
    "* truth_cat => `dc2_truth_run1.2_variable_summary`\n",
    "* truth_lc => `dc2_truth_run1.2_variable_lightcurve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inject gcr-catalogs that supports DIA source into path.\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires issues/337 to fix obshistid query.\n",
    "sys.path.insert(0, '/global/homes/b/bos0109/desc/gcr-catalogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsst.afw.display as afwDisplay\n",
    "import lsst.afw.geom as afwGeom\n",
    "from lsst.daf.persistence import Butler\n",
    "from lsst.geom import SpherePoint\n",
    "import lsst.geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GCRCatalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = '/global/cscratch1/sd/rearmstr/new_templates/diffim_template'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "butler = Butler(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaSrc = GCRCatalogs.load_catalog('dc2_dia_source_run1.2p_test')\n",
    "diaObject = GCRCatalogs.load_catalog('dc2_dia_object_run1.2p_test')\n",
    "truth_cat = GCRCatalogs.load_catalog('dc2_truth_run1.2_variable_summary')\n",
    "truth_lc = GCRCatalogs.load_catalog('dc2_truth_run1.2_variable_lightcurve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_cat.list_all_quantities(include_native=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many objects are there in truth cat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(truth_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_qtys = ['galaxy_id', 'redshift', 'ra', \n",
    "            'sprinkled', 'sn', 'agn', 'dec', 'uniqueId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_cat = pd.DataFrame(truth_cat.get_quantities(all_qtys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we split the catalog into AGN sources and SNe, we will be working with SNe only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sn = truth_cat[truth_cat.sn==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_agn = truth_cat[truth_cat.agn==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('''We have a total of {} SNe, {} AGNs and they add up to {}'''.format(\n",
    "    len(all_sn), len(all_agn), len(all_sn)+len(all_agn)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine, we have everything splitted in two.  \n",
    "We may have to filter to get only tract 4849 and patch (6, 6) objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract = 4849\n",
    "patch = (6, 6)\n",
    "\n",
    "skymap = butler.get('deepCoadd_skyMap')\n",
    "tract_info = skymap[tract]\n",
    "\n",
    "foo = tract_info.getPatchInfo(patch)\n",
    "\n",
    "bar = foo.getOuterSkyPolygon(tract_info.getWcs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# he uses lsst.afwGeom Box2D to parse the tract bounding box into lsst's stack language\n",
    "tract_box = afwGeom.Box2D(tract_info.getBBox())\n",
    "\n",
    "tract_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_pos_list = tract_box.getCorners()\n",
    "\n",
    "tract_pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_patch_box = tract_info.getPatchInfo(patch).getOuterBBox()\n",
    "tract_patch_pos_list = tract_patch_box.getCorners()\n",
    "# Cast to Point2D, because pixelToSky below will refuse to work with a Point2I object.\n",
    "tract_patch_pos_list = [afwGeom.Point2D(tp) for tp in tract_patch_pos_list]\n",
    "\n",
    "wcs = tract_info.getWcs()\n",
    "corners = wcs.pixelToSky(tract_patch_pos_list)\n",
    "corners = np.array([[c.getRa().asDegrees(), c.getDec().asDegrees()] for c in corners])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = corners[:, 0]\n",
    "dec = corners[:, 1]\n",
    "min_ra, max_ra = np.min(ra), np.max(ra)\n",
    "min_dec, max_dec = np.min(dec), np.max(dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min_ra, max_ra)\n",
    "print(min_dec, max_dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can filter the SNe catalog to be inside this coordinate box by using pandas filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = (all_sn.ra > min_ra) & (all_sn.ra < max_ra) & \\\n",
    "     (all_sn.dec > min_dec) & (all_sn.dec < max_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sn = all_sn[ff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = (all_agn.ra > min_ra) & (all_agn.ra < max_ra) & \\\n",
    "     (all_agn.dec > min_dec) & (all_agn.dec < max_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_sn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_agn = all_agn[ff]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets obtain their lightcurves. First we need the info on this light curve catalogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaSrc.get_catalog_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaObject.get_catalog_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diaSrc.list_all_quantities(include_native=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qq = diaObject.list_all_quantities(include_native=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quants = []\n",
    "for acol in qq:\n",
    "    try:\n",
    "        diaObject.get_quantities(acol)\n",
    "        quants.append(acol)\n",
    "    except:\n",
    "        print(acol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaOcols = ['ra', 'dec', 'diaObjectId', 'psFluxSigma_r', 'psFluxMean_r', 'psFluxMeanErr_r']\n",
    "filter_names = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "diaObject_cat = pd.DataFrame(diaObject.get_quantities(quants))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaObject_cat.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above was meant to filter the list of DIA Objects so we throw away bogus detections.   \n",
    "In the end, we just keep them, and can always filter them in the future."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ff = diaObject_cat['psFluxMean_r']/diaObject_cat['psFluxMeanErr_r'] > 3.\n",
    "\n",
    "print(len(diaObject_cat[ff]), 100*len(diaObject_cat[ff])/len(diaObject_cat))\n",
    "\n",
    "diaObject_cat = diaObject_cat[ff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaObject_positions = SkyCoord(diaObject_cat['ra'], diaObject_cat['dec'], unit='deg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sn_positions = SkyCoord(all_sn['ra'], all_sn['dec'], unit='deg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are building the arrays for astropy coordinate match to be feasible.  \n",
    "In any case, we perform the matching in both directions and keep the ones that had mutual agreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, d2d, d3d = all_sn_positions.match_to_catalog_sky(diaObject_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_, d2d_, d3d_ = diaObject_positions.match_to_catalog_sky(all_sn_positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the example of how to validate this two direction cross match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_[idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2d.to(u.arcsec)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do it for the whole sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = np.repeat(False, len(idx))\n",
    "matchO = np.repeat(False, len(idx_))\n",
    "not_matched = []\n",
    "for i in range(len(idx)):\n",
    "    if i==idx_[idx[i]]:\n",
    "        match[i] = True\n",
    "        matchO[idx[i]] = True\n",
    "    else:\n",
    "        not_matched.append([i, idx[i], idx_[idx[i]]])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(match), np.sum(matchO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a histogram of the match distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(d2d[match].to(u.arcsec).value, log=False)\n",
    "plt.hist(d2d[~match].to(u.arcsec).value, log=False, color='red')\n",
    "plt.vlines(x=2., ymin=0, ymax=100)\n",
    "plt.xlabel(r'Distance of match $\\Delta$ [arcsec]')\n",
    "plt.ylabel('N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sn_positions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_matched = np.array(not_matched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding this information to the SNe catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sn['matched'] = match\n",
    "all_sn['match_ang_dist'] = d2d.to(u.arcsec)\n",
    "all_sn['dia_row'] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matchO.shape, len(diaObject_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the equivalent information to the DIA Object catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaObject_cat['match'] = matchO\n",
    "diaObject_cat['sn_row'] = idx_\n",
    "diaObject_cat['match_ang_dist'] = d2d_.to(u.arcsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No we can see the angular distance calculated by the matching routine.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(d2d_[matchO].to(u.arcsec).value, log=True, label='SN to DIA')\n",
    "plt.hist(d2d_[~matchO].to(u.arcsec).value, log=False, color='red', alpha=0.1, label='DIA to SN')\n",
    "plt.vlines(x=2.5, ymin=0, ymax=100)\n",
    "#plt.xscale('log')\n",
    "plt.xlabel(r'Angular Distance $\\Delta [arcsec]')\n",
    "plt.ylabel('N')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make a sky chart plot of the positions of the DIA and SN in the sky.  \n",
    "Blue is the SNe catalog, red are the DIA objects.\n",
    "\n",
    "In the right panel we have the matched DIA objects. We see that we have much less density of objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(121)\n",
    "plt.title('SN cat / DIA cat')\n",
    "plt.plot(all_sn.ra, all_sn.dec, '.', alpha=0.3, label='Truth')\n",
    "plt.plot(diaObject_cat.ra, diaObject_cat.dec, 'rx', alpha=0.2, label='DIA')\n",
    "plt.xlabel('RA [deg]')\n",
    "plt.ylabel('Dec [deg]')\n",
    "plt.legend(loc='best')\n",
    "plt.gca().invert_xaxis()\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('SN cat / DIA cat (matched)')\n",
    "plt.plot(all_sn.ra, all_sn.dec, '.', alpha=0.5, label='Truth')\n",
    "plt.plot(diaObject_cat[matchO].ra, diaObject_cat[matchO].dec, 'rx', alpha=0.5, label='DIA')\n",
    "plt.xlim(52.94, 53.21)\n",
    "plt.ylim(-28.455, -28.23)\n",
    "plt.gca().invert_xaxis()\n",
    "plt.xlabel('RA [deg]')\n",
    "plt.ylabel('Dec [deg]')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaObject_cat.to_csv('diaObject_matched.csv')\n",
    "all_sn.to_csv('all_sn_matched.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two tables, with the corresponding rows matched. \n",
    "\n",
    "We could find useful to have everything in the same table, so we are going to build a unified catalog of matched and orphan objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaObject_cat['sn_Uid'] = None\n",
    "diaObject_cat['sn_galaxy_id'] = None\n",
    "diaObject_cat['sn_ra'] = None\n",
    "diaObject_cat['sn_dec'] = None\n",
    "diaObject_cat['sn_redshift'] = None\n",
    "diaObject_cat['sn_sprinkled'] = None\n",
    "diaObject_cat['sn_matched'] = None\n",
    "diaObject_cat['sn_match_ang_dist'] = None\n",
    "diaObject_cat['sn_dia_row'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_row, arow in diaObject_cat.loc[diaObject_cat['match']].iterrows():\n",
    "    allsnrow = all_sn.iloc[arow['sn_row']]\n",
    "    if allsnrow['matched']:\n",
    "        if allsnrow['dia_row']==i_row:\n",
    "            \n",
    "            diaObject_cat.loc[i_row, 'sn_Uid'] = allsnrow['uniqueId']\n",
    "            diaObject_cat.loc[i_row, 'sn_galaxy_id'] = allsnrow['galaxy_id']\n",
    "            diaObject_cat.loc[i_row, 'sn_ra'] = allsnrow['ra']\n",
    "            diaObject_cat.loc[i_row, 'sn_dec'] = allsnrow['dec']\n",
    "            diaObject_cat.loc[i_row, 'sn_redshift'] = allsnrow['redshift']\n",
    "            diaObject_cat.loc[i_row, 'sn_sprinkled'] = allsnrow['sprinkled']\n",
    "            diaObject_cat.loc[i_row, 'sn_matched'] = True\n",
    "            diaObject_cat.loc[i_row, 'sn_msn_match_ang_distatch_ang_dist'] = allsnrow['match_ang_dist']\n",
    "            diaObject_cat.loc[i_row, 'sn_dia_row'] = allsnrow['dia_row']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaObject_cat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate = {'sprinkled': \"sn_sprinkled\", \n",
    "             'ra': \"sn_ra\", \n",
    "             'dec': \"sn_dec\",\n",
    "             'redshift': \"sn_redshift\", \n",
    "             'uniqueId': \"sn_Uid\", \n",
    "             'galaxy_id': \"sn_galaxy_id\",\n",
    "             'matched': \"sn_matched\", \n",
    "             'match_ang_dist': \"sn_match_ang_dist\",\n",
    "             'dia_row': \"sn_dia_row\"}\n",
    "\n",
    "tr_cols = ['sprinkled', 'ra', 'redshift', 'uniqueId', \n",
    "           'galaxy_id', 'dec', 'matched', 'match_ang_dist', 'dia_row']\n",
    "\n",
    "appendable = all_sn[tr_cols].copy()\n",
    "appendable.rename(columns=translate, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullcat = diaObject_cat.append(appendable[appendable['sn_matched']==False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaObject_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now, everything in one single table, merged by angular matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of matched SN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check some properties of the matched SN, and we find some strange results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_sn[all_sn['matched']]['redshift'], histtype='step', lw=2, label='matched')\n",
    "plt.hist(all_sn[~all_sn['matched']]['redshift'], histtype='step', lw=2, label='Not matched')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('True Redshift z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot shows that in the matching we found SNe at really high redshifts, which sound too good to be true. Maybe an angular matching is not the best way, and this motivates the future _time-match_ process in the individual lightcurves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_sn[all_sn['sprinkled']==1]['redshift'], histtype='step', lw=2, label='sprinkled')\n",
    "plt.hist(all_sn[all_sn['sprinkled']==0]['redshift'], histtype='step', lw=2, label='Not sprinkled')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('True Redshift z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot is also unexpected to me. I thought that sprinkled sources are the ones that had higher redshifts. This would need further confirmation (I am not a sprinkled sources expert)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_sn[all_sn['matched']]['sprinkled'], histtype='step', lw=2, label='matched')\n",
    "plt.hist(all_sn[~all_sn['matched']]['sprinkled'], histtype='step', lw=2, label='Not matched')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Sprinkled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "## Asking for the lightcurves\n",
    "\n",
    "Now we are going to ask for the individual light curves and produce a full catalog of matched/not-matched sources.  \n",
    "The target catalog should contain a set of columns that include DIA data, as well as SN truth data.  \n",
    "The whole group of columns will contain information only if we have a match in coordinates as well as in _time_. We are actually finding coincident epochs in the DIA and truth SN lightcurves.  \n",
    "In the case that we don't find match, a subset of our columns shall have then missing information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snlc_cols = truth_lc.list_all_quantities(include_native=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snlc_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialc_cols = ['visit', 'mjd', 'psFlux', 'psFluxErr', 'mag', 'mag_err',  'isDipole', 'apFlux',\n",
    "               'apFluxErr', 'filter', 'ra', 'dec', 'diaObjectId', 'id', 'diaSourceId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combocols = ['dia_'+col for col in dialc_cols]\n",
    "combocols.extend(['sn_'+col for col in snlc_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WARNING\n",
    "\n",
    "The way this is programmed is favoring readability against performance. I took this direction so the code can be shared.  \n",
    "\n",
    "For this reason it takes a couple of hours, since it queries every single lightcurve in DIA and SN truth catalogs.  \n",
    "If you don't have time to wait for this, the table has been saved and after this block cell you can read it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = 0\n",
    "log_buffer = ''\n",
    "filter_names = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "fullcat['sn_lc_len'] = 0\n",
    "fullcat['dia_lc_len'] = 0\n",
    "lc_rows = [combocols]\n",
    "aminute = 1./(24*60.)\n",
    "for i, arow in fullcat.iterrows():\n",
    "    #if im> 5: break\n",
    "    # what kind of row is this?\n",
    "    if arow['match'] and arow['sn_matched']:\n",
    "        #  we have a match in space\n",
    "        #  asking for the light curves\n",
    "    \n",
    "        #first SN\n",
    "        ff = ['uniqueId == {}'.format(arow[\"sn_Uid\"])]\n",
    "        sn_lc = truth_lc.get_quantities(snlc_cols, native_filters=ff)\n",
    "        sn_lc = pd.DataFrame(sn_lc)\n",
    "        # if length is zero then mark as ??\n",
    "        snlc_flength = len(sn_lc)\n",
    "        fullcat.loc[i, 'sn_lc_len'] = snlc_length\n",
    "\n",
    "        #then DIA\n",
    "        diaObjectId = arow['diaObjectId']  # get the diaObjectId\n",
    "        # We can't use a direct filters = match in the GCR wrapper for the diaSrc table.\n",
    "        # So we have to use a lambda function here to match the ID\n",
    "        dia_lc = diaSrc.get_quantities(dialc_cols, filters=[(lambda x: x == diaObjectId, 'diaObjectId')])\n",
    "        dia_lc = pd.DataFrame(dia_lc)\n",
    "        dia_lc = dia_lc.sort_values('mjd')\n",
    "        dialc_flength = len(dia_lc)\n",
    "        fullcat.loc[i, 'dia_lc_len'] = dialc_lenght\n",
    "        \n",
    "        # write our pseudo log\n",
    "        log_buffer += f\"\"\"found {snlc_length} points in the truth lightcurve, and found {dialc_lenght} in the DIA \\n\"\"\"\n",
    "        \n",
    "        \n",
    "        for ifilter, nfilter in enumerate(filter_names):\n",
    "                        \n",
    "            dia_lc_filtered = dia_lc[dia_lc['filter']==nfilter]\n",
    "            sn_lc_filtered = sn_lc[sn_lc['filter']==ifilter]\n",
    "\n",
    "            dialc_length = len(dia_lc_filtered)\n",
    "            snlc_length = len(sn_lc_filtered)\n",
    "\n",
    "            # check existent data in the light curves\n",
    "            if dialc_length is 0 and snlc_length is 0:\n",
    "                continue     \n",
    "            elif dialc_length is 0 and snlc_length is not 0:\n",
    "                for k_epoch, datarow in sn_lc.iterrows():\n",
    "                    newcomborow = len(dialc_cols)*[None]\n",
    "                    newcomborow.extend([datarow[sncol] for sncol in snlc_cols])\n",
    "                    lc_rows.append(newcomborow)\n",
    "            elif dialc_length is not 0 and snlc_length is 0:\n",
    "                for j_epoch, datarow in dia_lc.iterrows():\n",
    "                    newcomborow = [datarow[diacol] for diacol in dialc_cols]\n",
    "                    newcomborow.extend(len(snlc_cols)*[None])\n",
    "                    lc_rows.append(newcomborow)\n",
    "            else:  # here we do match the catalogs in time\n",
    "                idxs = []\n",
    "                for iepoch, sndata in sn_lc_filtered.iterrows():\n",
    "                    t = sndata['mjd']\n",
    "                    deltas = np.abs(t-dia_lc_filtered['mjd'])\n",
    "                    mindt = np.min(deltas)\n",
    "                    if mindt<=5*aminute:\n",
    "                        dia_idx = int(np.where(deltas==np.min(deltas))[0][0])\n",
    "                        idxs.append(dia_idx)\n",
    "                        dia_datarow = [dia_lc_filtered.iloc[dia_idx][a_col] for a_col in dialc_cols]\n",
    "                        lc_rows.append(dia_datarow+[sndata[acol] for acol in snlc_cols])\n",
    "                    else:\n",
    "                        lc_rows.append(len(dialc_cols)*[None]+[sndata[acol] for acol in snlc_cols])\n",
    "                # take care of the dia rows not used\n",
    "                for iepoch, diadata in dia_lc_filtered.iterrows():\n",
    "                    if iepoch not in idxs:\n",
    "                        #print(iepoch)\n",
    "                        dia_datarow = [diadata[a_col] for a_col in dialc_cols]\n",
    "                        lc_rows.append(dia_datarow+len(snlc_cols)*[None])\n",
    "        #im+=1\n",
    "        \n",
    "    elif not arow['match'] and not arow['sn_matched']:\n",
    "        log_buffer += 'This combination are orphan objects. \\n'\n",
    "        if arow['diaObjectId'] is not None:\n",
    "            #then DIA\n",
    "            diaObjectId = arow['diaObjectId']  # get the diaObjectId\n",
    "            # We can't use a direct filters = match in the GCR wrapper for the diaSrc table.\n",
    "            # So we have to use a lambda function here to match the ID\n",
    "            dia_lc = diaSrc.get_quantities(dialc_cols, filters=[(lambda x: x == diaObjectId, 'diaObjectId')])\n",
    "            dia_lc = pd.DataFrame(dia_lc)\n",
    "            dia_lc = dia_lc.sort_values('mjd')\n",
    "            dialc_flength = len(dia_lc)\n",
    "            fullcat.loc[i, 'dia_lc_len'] = dialc_lenght\n",
    "            for j_epoch, datarow in dia_lc.iterrows():\n",
    "                newcomborow = [datarow[diacol] for diacol in dialc_cols]\n",
    "                newcomborow.extend(len(snlc_cols)*[None])\n",
    "                lc_rows.append(newcomborow)\n",
    "            \n",
    "        elif arow['snUid'] is not None:\n",
    "            #first SN\n",
    "            ff = ['uniqueId == {}'.format(arow[\"sn_Uid\"])]\n",
    "            sn_lc = truth_lc.get_quantities(snlc_cols, native_filters=ff)\n",
    "            sn_lc = pd.DataFrame(sn_lc)\n",
    "            # if length is zero then mark as ??\n",
    "            snlc_flength = len(sn_lc)\n",
    "            fullcat.loc[i, 'sn_lc_len'] = snlc_length\n",
    "            for k_epoch, datarow in sn_lc.iterrows():\n",
    "                newcomborow = len(dialc_cols)*[None]\n",
    "                newcomborow.extend([datarow[sncol] for sncol in snlc_cols])\n",
    "                lc_rows.append(newcomborow)\n",
    "                \n",
    "    elif arow['match'] and not arow['sn_matched']:\n",
    "        print('HALT 3')\n",
    "        log_buffer += 'This combination should not exist. Will search for DIA LC \\n'\n",
    "    else:\n",
    "        print('HALT 4')\n",
    "        log_buffer += 'This combination should not exist. Will search for SN lc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flc_match = pd.DataFrame(lc_rows[1:], columns=lc_rows[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flc_match['filter'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffd = pd.notnull(flc_match['dia_diaSourceId'])\n",
    "ffs = pd.notnull(flc_match['sn_uniqueId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flc_match.loc[ffd, 'filter'] = flc_match.loc[ffd, 'dia_filter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flc_match.loc[ffs, 'filter'] = [filter_names[int(fcode)] for fcode in flc_match.loc[ffs, 'sn_filter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flc_match.to_csv('flc_match.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flc_match = pd.read_csv('flc_match.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffd = pd.notnull(flc_match['dia_diaSourceId'])\n",
    "ffs = pd.notnull(flc_match['sn_uniqueId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_snepochs = flc_match[ffs&ffd]\n",
    "lost_snepochs = flc_match[~ffd & ffs]\n",
    "orphan_depocs = flc_match[ffd & ~ffs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_snepochs = flc_match[ffs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting samples\n",
    "----------\n",
    "\n",
    "Now we are producing a couple of plots, showing some differences in DIA vs SN truth, using the matched epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(221)\n",
    "plt.hist(found_snepochs.sn_mag-found_snepochs.dia_mag)\n",
    "plt.xlabel('truth_mag - dia_mag')\n",
    "plt.ylabel('N')\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.hist((found_snepochs.sn_mjd-found_snepochs.dia_mjd)*24.*60, log=False, bins=10)\n",
    "plt.xscale('linear')\n",
    "plt.xlabel('truth_mjd - dia_mjd')\n",
    "plt.ylabel('N')\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.hist(found_snepochs.dia_apFlux/found_snepochs.dia_apFluxErr)\n",
    "plt.xlim(-50, 150)\n",
    "plt.xlabel('dia_apFlux/dia_apFluxErr')\n",
    "plt.ylabel('N')\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.plot(found_snepochs.sn_mjd, found_snepochs.sn_mag, 'b.', label='Truth mags')\n",
    "plt.plot(found_snepochs.dia_mjd, found_snepochs.dia_mag, 'r.', label='DIA mags')\n",
    "plt.legend(loc='best')\n",
    "plt.ylim(30, 19.5)\n",
    "plt.xlabel('MJD')\n",
    "plt.ylabel('mag')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_snepochs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(found_snepochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_snepochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficiency graphs\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function goes through the true supernovae and counts how many we have found in magnitude bins.  \n",
    "This quantity is called the TP, or True Positives.  \n",
    "We also calculate the False Positives, and the Recall R value, which is the ratio of TP to the total amount of SNe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalls_filter(cat, filter='g', bins=np.arange(21, 26, 0.5)):\n",
    "    inj = cat[cat['filter']==filter].copy()\n",
    "    inj = inj.sort_values('sn_mag')\n",
    "    \n",
    "    ind = np.digitize(inj['sn_mag'], bins)\n",
    "    recalls = np.zeros((len(bins), 4))\n",
    "    for val, group in inj.groupby(ind):\n",
    "        \n",
    "        ibin = val-1\n",
    "        fn = np.sum(pd.notnull(group['sn_uniqueId']))\n",
    "        tp = np.sum(pd.notnull(group['dia_diaObjectId']))\n",
    "    \n",
    "        tot = len(group)\n",
    "        recall = tp/(tp+fn)\n",
    "        recalls[ibin, :] = tp, fn, recall, tot\n",
    "    \n",
    "    return(recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(18, 40, .5)\n",
    "recalls_g = recalls_filter(all_snepochs, filter='g', bins=bins)\n",
    "recalls_r = recalls_filter(all_snepochs, filter='r', bins=bins)\n",
    "recalls_i = recalls_filter(all_snepochs, filter='i', bins=bins)\n",
    "recalls_z = recalls_filter(all_snepochs, filter='z', bins=bins)\n",
    "recalls_y = recalls_filter(all_snepochs, filter='y', bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(recalls_g, axis=0))\n",
    "print(np.sum(recalls_r, axis=0))\n",
    "print(np.sum(recalls_i, axis=0))\n",
    "print(np.sum(recalls_z, axis=0))\n",
    "print(np.sum(recalls_y, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(bins, recalls_g[:, 2], 'x-', color='green', label='g band')\n",
    "plt.plot(bins, recalls_r[:, 2], '.-', color='red', label='r band')\n",
    "plt.plot(bins, recalls_i[:, 2], '-', color='magenta', label='i band')\n",
    "plt.plot(bins, recalls_z[:, 2], '--', color='blue', label='z band')\n",
    "plt.plot(bins, recalls_y[:, 2], '+-', color='black', label='y band')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('mag')\n",
    "plt.ylabel('recall R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(bins, recalls_g[:, 0], 'x-', color='green', label='g band')\n",
    "plt.plot(bins, recalls_r[:, 0], '.-', color='red', label='r band')\n",
    "plt.plot(bins, recalls_i[:, 0], '-', color='magenta', label='i band')\n",
    "plt.plot(bins, recalls_z[:, 0], '--', color='blue', label='z band')\n",
    "plt.plot(bins, recalls_y[:, 0], '+-', color='black', label='y band')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('mag')\n",
    "plt.ylabel('True positives TP')\n",
    "#plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(bins, recalls_g[:, 1], 'x-', color='green', label='g band')\n",
    "plt.plot(bins, recalls_r[:, 1], '.-', color='red', label='r band')\n",
    "plt.plot(bins, recalls_i[:, 1], '-', color='magenta', label='i band')\n",
    "plt.plot(bins, recalls_z[:, 1], '--', color='blue', label='z band')\n",
    "plt.plot(bins, recalls_y[:, 1], '+-', color='black', label='y band')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('mag')\n",
    "plt.ylabel('False Negatives FN')\n",
    "#plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New graphs\n",
    "\n",
    "Rahul B. asked for some more graphs on the results of this\n",
    "\n",
    "First one is to build the figure of the distribution of brightness for the total amount of objects.  \n",
    "Secondly we have the recall for the first bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.rcParams()\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.step(bins, recalls_g[:, 3], #'x-', \n",
    "         color='green', label='g band')\n",
    "plt.step(bins, recalls_r[:, 3], #'.-',\n",
    "         color='red', label='r band')\n",
    "plt.step(bins, recalls_i[:, 3], #'-', \n",
    "         color='magenta', label='i band')\n",
    "plt.step(bins, recalls_z[:, 3], #'--',\n",
    "         color='blue', label='z band')\n",
    "plt.step(bins, recalls_y[:, 3], #'+-',\n",
    "         color='black', label='y band')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('mag')\n",
    "plt.ylabel('Total amount')\n",
    "#plt.yscale('log')\n",
    "plt.xlim(16, 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.step(bins, recalls_g[:, 2], #'x-',\n",
    "         color='green', label='g band')\n",
    "plt.step(bins, recalls_r[:, 2], #'.-',\n",
    "         color='red', label='r band')\n",
    "plt.step(bins, recalls_i[:, 2], #'-', \n",
    "         color='magenta', label='i band')\n",
    "plt.step(bins, recalls_z[:, 2], #'--',\n",
    "         color='blue', label='z band')\n",
    "plt.step(bins, recalls_y[:, 2], #'+-',\n",
    "         color='black', label='y band')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('mag')\n",
    "plt.ylabel('recall R')\n",
    "plt.xlim(16, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in enumerate(filter_names):\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(log_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desc-stack",
   "language": "python",
   "name": "desc-stack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
