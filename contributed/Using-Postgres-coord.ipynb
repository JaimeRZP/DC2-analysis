{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing DC2 data in PostgreSQL at NERSC part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates use of the PostgreSQL database at NERSC.  Currently the only recommended datasets are the object catalogs for Run1.2i and Run1.2p\n",
    "\n",
    "You may skip to the code if you have already accessed PostgreSQL from another notebook.  The prerequisites are the same.\n",
    "\n",
    "### Prerequisites\n",
    "* A file ~/.pgpass containing a line like this:\n",
    "\n",
    "`nerscdb03.nersc.gov:54432:desc_dc2_drp:desc_dc2_drp_user:`_password_\n",
    "\n",
    "This line allows you to use the desc_dc2_drp_user account, which has *SELECT* privileges on the database, without entering a password in plain text. There is a separate account for adding to or modifying the database. .pgpass must be protected so that only owner may read and write it.\n",
    " \n",
    "You can obtain the file by running the script `/global/common/software/lsst/dbaccess/postgres_reader.sh`.  It will copy a suitable file to your home directory and set permissions.  \n",
    "\n",
    "If you already have a `.pgpass` file in your home directory the script will stop without doing anything to avoid clobbering your file.  In that case, see the file `reader.pgpass` in the same directory.  You can merge it into your `.pgpass` file by hand.  \n",
    "\n",
    "* Access to the psycopg2 package which provides a Python interface to PostgreSQL. If it's not already available, do a local pip install.  Then you may have to \n",
    "  * put a line like this in your .bashrc.ext:  \n",
    "    ```$DESCPYTHONPATH=~/.local/pythonpath3.6/site-packages```\n",
    "  * restart your jupyter-dev server\n",
    "  \n",
    "This notebook uses psycopg2 directly for queries.  It is also possible to use sqlalchemy but you will still need a PostgreSQL driver. Of these psycopg2 is the most popular.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the db connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname = 'desc_dc2_drp'\n",
    "dbuser = 'desc_dc2_drp_user'\n",
    "dbhost = 'nerscdb03.nersc.gov'\n",
    "dbconfig = {'dbname' : dbname, 'user' : dbuser, 'host' : dbhost}\n",
    "dbconn = psycopg2.connect(**dbconfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tables for the Run1.2i data as well as a view to make dpdd quantities more easily accessible are in the `schema` (acts like a namespace) `run12i`.  To reference, say, a table called `position` for Run1.2i use `run12i.position`. For Run1.2p the schema name is `run12p_v4`.\n",
    "\n",
    "To find out which datasets are available and by what schema names, query the table `run_provenance`. It's in a special schema known as `public` which does not normally need to be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['schema_name', 'run_designation','simulation_program', 'db_ingest', 'remarks']\n",
    "prov_query = 'SELECT '  + ','.join(cols) + ' from run_provenance'\n",
    "with dbconn.cursor() as cursor:\n",
    "    cursor.execute(prov_query)\n",
    "    fmt = '{0!s:13} {1!s:16} {2!s:18} {3!s:12} {4!s}'\n",
    "    print(fmt.format(cols[0], cols[1], cols[2], cols[3], cols[4]))\n",
    "    for record in cursor:\n",
    "        print(fmt.format(record[0], record[1], record[2], record[3], record[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one of the supported datasets\n",
    "schema = 'run12p_v4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a special system schema, **information_schema**, which contains tables describing the structure of user tables. Of these **information_schema.columns** is most likely to be useful. The following lists all tables and views belonging to our chosen schema. (I will use the convention of writing SQL keywords in all caps in queries. It's not necessary; the SQL interpreter ignores case.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = \"SELECT DISTINCT table_name FROM information_schema.columns WHERE table_schema='{schema}' ORDER BY table_name\".format(**locals())\n",
    "with dbconn.cursor() as cursor:\n",
    "    # Typically could have several queries in this block\n",
    "    cursor.execute(q1)\n",
    "    for record in cursor:\n",
    "        print(record[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the exception of **dpdd** and **dpdd_plus** all items listed are the names of database tables.  Each (other than **\\_temp:forced\\_patch** which is of interest only while data are being ingested) has rows of data, one per object in the catalog. The rows consist of \"native quantities\" as produced by running the dm stack on the simulated data. **dpdd** is a _view_* making the quantities identified in (ref) available.     Information is broken across several tables because there are too many columns for a single table. All tables have a field ```object_id```. In the **dpdd** view it's called ```objectId``` because that's the official name for it.  Here is a list of all quantities in the **dpdd** view. Note the database ignores case; all quantities appear in lower case only.\n",
    "\n",
    "*A _view_ definition consists of references to quantities stored in the tables or computable from them; the view has no data of its own. The view name is used in queries just like a table name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = 'dpdd_plus'\n",
    "q2 = \"SELECT column_name, data_type FROM information_schema.columns WHERE table_schema='{schema}' AND table_name='{tbl}' order by column_name \".format(**locals())\n",
    "print(q2)\n",
    "with dbconn.cursor() as cursor:\n",
    "    cursor.execute(q2)\n",
    "    records = cursor.fetchall()\n",
    "    print(\"There are {} columns in table {}.  They are:\\n\".format(len(records), tbl))\n",
    "    print(\"Name                                                     Data Type\")\n",
    "    for record in records:\n",
    "        print(\"{0!s:55}  {1!s:20}\".format(record[0], record[1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a similar query for the **position** table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using coord\n",
    "The difference between the views **dpdd** an **dpdd_plus** is that the latter has an extra column, `coord`, which is an alternate way (other than `ra` and `dec`) to express location.  A `coord` value is a triple of doubles representing a position on a sphere in units of arcseconds. This column is indexed, which can make certain calculations faster. In particular, using the functions `conesearch` and `boxsearch` (which take a `coord` as input) rather than starting with `ra` and `dec` makes queries much faster.  There are also functions to translate between `coord` and `(ra, dec)`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Star brightness\n",
    "Pick a band and get an idea of magnitude distribution with a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_cuts = 'clean and (extendedness < 0.1) '\n",
    "pop = 'Stars'\n",
    "#global_cuts = 'clean and (extendedness > 0.9) '\n",
    "#pop = 'Galaxies'\n",
    "min_SNR = 25\n",
    "max_err = 1/min_SNR\n",
    "band = 'i'\n",
    "mag_col = 'mag_' + band\n",
    "#band_cuts = ' (magerr_{band} < {max_err}) and (mag_{band} < 15.8)'.format(**locals())\n",
    "band_cuts = ' (magerr_{band} < {max_err}) '.format(**locals())\n",
    "where = ' WHERE ' + global_cuts + ' AND ' + band_cuts  \n",
    "\n",
    "q5 = \"SELECT mag_{band}, ra, dec FROM {schema}.dpdd \".format(**locals()) + where\n",
    "print(q5)\n",
    "records = []\n",
    "with dbconn.cursor() as cursor:\n",
    "    %time cursor.execute(q5)\n",
    "    records = cursor.fetchall()\n",
    "    nObj = len(records)\n",
    "    print('{} objects found '.format(nObj))\n",
    "    \n",
    "mags = pd.DataFrame(records, columns=[mag_col, 'ra', 'dec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.xlabel(mag_col)\n",
    "plt.ylabel('count')\n",
    "plt.suptitle(pop, size='xx-large', y=0.92)\n",
    "plt.hist(mags[mag_col], bins=20, color='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a cut on magnitude to get to make a more visually pleasing scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_max = 15.5\n",
    "nda = mags.values\n",
    "nrow = 0\n",
    "for r in nda:\n",
    "    if r[0] < mag_max: nrow += 1\n",
    "print('After filtering left with {} objects'.format(nrow))\n",
    "nda_filt = np.ndarray((nrow, nda.shape[1]), dtype=mags.dtypes[0])\n",
    "irow = 0\n",
    "for r in nda:\n",
    "    if r[0] < mag_max: \n",
    "        nda_filt[irow] = r\n",
    "        irow += 1\n",
    "mags_filt = pd.DataFrame(data=nda_filt, columns=mags.columns)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.xlabel('ra')\n",
    "plt.ylabel('dec')\n",
    "plt.suptitle(pop, size='xx-large', y=0.92)\n",
    "p = plt.scatter(mags_filt['ra'], mags_filt['dec'], color='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cone search\n",
    "Find all stars satisfying quality cuts within a fixed radius (in arcseconds) of a particular coordinate.  The function `coneSearch` returns true if `coord` is within the cone centered at (ra, dec) of the specified radius, measured in arcseconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = 54.5\n",
    "decl = -31.4\n",
    "radius = 240.0\n",
    "where = ' where (magerr_{band} < {max_err}) and clean and (extendedness < 0.1) and coneSearch(coord, {ra}, {decl}, {radius})'\n",
    "qcone = ('SELECT ra, dec, mag_{band} from {schema}.dpdd_plus  ' + where).format(**locals())\n",
    "print(qcone)\n",
    "with dbconn.cursor() as cursor:\n",
    "    %time cursor.execute(qcone)\n",
    "    records = cursor.fetchall()\n",
    "    nObj = len(records)\n",
    "    print('{} objects found '.format(nObj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmags = pd.DataFrame(records, columns=['ra', 'dec', mag_col])\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.xlabel('ra')\n",
    "plt.ylabel('dec')\n",
    "plt.suptitle(pop + ' Cone search', size='xx-large', y=0.92)\n",
    "p = plt.scatter(cmags['ra'], cmags['dec'], color='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box search\n",
    "Find all stars, subject to quality cuts, with the specified ra and dec bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra1 = 54.4\n",
    "ra2 = 54.8\n",
    "decl1 = -31.6\n",
    "decl2 = -31.3\n",
    "\n",
    "where = ' where (magerr_{band} < {max_err}) and clean and (extendedness < 0.1) and boxSearch(coord, {ra1}, {ra2},{decl1}, {decl2})'\n",
    "qbox = ('SELECT ra, dec, mag_{band} from {schema}.dpdd_plus  ' + where).format(**locals())\n",
    "print(qbox)\n",
    "with dbconn.cursor() as cursor:\n",
    "    %time cursor.execute(qbox)\n",
    "    records = cursor.fetchall()\n",
    "    nObj = len(records)\n",
    "    print('{} objects found '.format(nObj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmags = pd.DataFrame(records, columns=['ra', 'dec', mag_col])\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.xlabel('ra')\n",
    "plt.ylabel('dec')\n",
    "plt.suptitle(pop + ' Box search', size='xx-large', y=0.92)\n",
    "p = plt.scatter(bmags['ra'], bmags['dec'], color='y')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desc-python",
   "language": "python",
   "name": "desc-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
